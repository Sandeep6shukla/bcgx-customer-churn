{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df467524",
   "metadata": {},
   "source": [
    "# EDA Notebook — BCG X Task 2\n",
    "\n",
    "This notebook starts from the **starter template provided** and extends it with additional EDA steps focused on understanding drivers of churn (price sensitivity, consumption, margins, and customer service channels). It expects `client_data.csv` and `price_data.csv` in the same folder as the notebook. The code includes fallbacks to the uploaded filenames if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e173a5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "# Set plot style\n",
    "sns.set(color_codes=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25bd7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try common filenames, otherwise use the uploaded versions with (1)\n",
    "from pathlib import Path\n",
    "\n",
    "candidates = [\"./client_data.csv\", \"./client_data (1).csv\", \"/mnt/data/client_data (1).csv\", \"/mnt/data/client_data.csv\"]\n",
    "p_candidates = [\"./price_data.csv\", \"./price_data (1).csv\", \"/mnt/data/price_data (1).csv\", \"/mnt/data/price_data.csv\"]\n",
    "\n",
    "client_path = None\n",
    "price_path = None\n",
    "\n",
    "for p in candidates:\n",
    "    if Path(p).exists():\n",
    "        client_path = p\n",
    "        break\n",
    "\n",
    "for p in p_candidates:\n",
    "    if Path(p).exists():\n",
    "        price_path = p\n",
    "        break\n",
    "\n",
    "if client_path is None or price_path is None:\n",
    "    raise FileNotFoundError(f\"Could not find client_data.csv or price_data.csv. Checked: {candidates} and {p_candidates}\")\n",
    "\n",
    "print(\"Using:\", client_path, price_path)\n",
    "client_df = pd.read_csv(client_path)\n",
    "price_df = pd.read_csv(price_path)\n",
    "\n",
    "# Quick head\n",
    "display(client_df.head(3))\n",
    "display(price_df.head(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7876f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data types and quick stats\n",
    "print(\"Client data info:\")\n",
    "client_df.info()\n",
    "print(\"\\nPrice data info:\")\n",
    "price_df.info()\n",
    "\n",
    "print(\"\\nNumerical description for client_df:\")\n",
    "display(client_df.describe(include=[np.number]).T)\n",
    "\n",
    "print(\"\\nCategorical / object counts (sample):\")\n",
    "for col in client_df.select_dtypes(include=['object','bool','category']).columns[:10]:\n",
    "    print(f\"--- {col} ---\")\n",
    "    print(client_df[col].value_counts(dropna=False).head(10))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1833b916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert common date columns and categorical flags\n",
    "date_cols = [c for c in client_df.columns if 'date' in c.lower()]\n",
    "for c in date_cols:\n",
    "    try:\n",
    "        client_df[c] = pd.to_datetime(client_df[c], errors='coerce')\n",
    "    except Exception as e:\n",
    "        print(\"Could not convert\", c, e)\n",
    "\n",
    "# Convert price date\n",
    "if 'price_date' in price_df.columns:\n",
    "    price_df['price_date'] = pd.to_datetime(price_df['price_date'], errors='coerce')\n",
    "\n",
    "# Convert boolean-like columns\n",
    "bool_like = [c for c in client_df.columns if client_df[c].dropna().isin([0,1]).all() and client_df[c].nunique()<=2]\n",
    "# keep churn as numeric but show distribution\n",
    "print(\"Churn value counts:\")\n",
    "print(client_df['churn'].value_counts(dropna=False))\n",
    "\n",
    "# Ensure categorical dtype for some columns\n",
    "cat_cols = ['channel_sales','origin_up','has_gas']\n",
    "for c in cat_cols:\n",
    "    if c in client_df.columns:\n",
    "        client_df[c] = client_df[c].astype('category')\n",
    "\n",
    "print(\"\\nAfter conversions:\")\n",
    "client_df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1a5121",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values and unique counts\n",
    "missing = client_df.isnull().sum().sort_values(ascending=False)\n",
    "display(missing[missing>0])\n",
    "\n",
    "uniques = client_df.nunique().sort_values()\n",
    "display(uniques.head(20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb9660e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper plotting functions from starter notebook\n",
    "\n",
    "def annotate_stacked_bars(ax, pad=0.99, colour=\"white\", textsize=13):\n",
    "    for p in ax.patches:\n",
    "        value = str(round(p.get_height(),1))\n",
    "        if value == '0.0':\n",
    "            continue\n",
    "        ax.annotate(\n",
    "            value,\n",
    "            ((p.get_x()+ p.get_width()/2)*pad-0.05, (p.get_y()+p.get_height()/2)*pad),\n",
    "            color=colour,\n",
    "            size=textsize\n",
    "        )\n",
    "\n",
    "def plot_stacked_bars(dataframe, title_, size_=(18, 10), rot_=0, legend_=\"upper right\"):\n",
    "    ax = dataframe.plot(\n",
    "        kind=\"bar\",\n",
    "        stacked=True,\n",
    "        figsize=size_,\n",
    "        rot=rot_,\n",
    "        title=title_\n",
    "    )\n",
    "    annotate_stacked_bars(ax, textsize=14)\n",
    "    plt.legend([\"Retention\", \"Churn\"], loc=legend_)\n",
    "    plt.ylabel(\"Company base (%)\")\n",
    "    plt.show()\n",
    "\n",
    "def plot_distribution(dataframe, column, ax, bins_=50):\n",
    "    temp = pd.DataFrame({\"Retention\": dataframe[dataframe[\"churn\"]==0][column],\n",
    "    \"Churn\":dataframe[dataframe[\"churn\"]==1][column]})\n",
    "    temp[[\"Retention\",\"Churn\"]].plot(kind='hist', bins=bins_, ax=ax, stacked=True)\n",
    "    ax.set_xlabel(column)\n",
    "    ax.ticklabel_format(style='plain', axis='x')\n",
    "\n",
    "# Churn overview\n",
    "churn = client_df[['id', 'churn']].copy()\n",
    "churn.columns = ['Companies', 'churn']\n",
    "churn_total = churn.groupby(churn['churn']).count()\n",
    "churn_percentage = churn_total / churn_total.sum() * 100\n",
    "plot_stacked_bars(churn_percentage.transpose(), \"Churning status\", (6, 4), legend_=\"lower right\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57d4966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consumption distributions: cons_12m and cons_last_month if available\n",
    "cons_cols = [c for c in ['cons_12m','cons_last_month','cons_gas_12m'] if c in client_df.columns]\n",
    "if len(cons_cols)>0:\n",
    "    fig, axs = plt.subplots(nrows=len(cons_cols), figsize=(10,4*len(cons_cols)))\n",
    "    if len(cons_cols)==1:\n",
    "        axs = [axs]\n",
    "    for ax,col in zip(axs,cons_cols):\n",
    "        plot_distribution(client_df, col, ax, bins_=80)\n",
    "        ax.set_title(f\"Distribution of {col} (Retention vs Churn)\")\n",
    "    plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ea39a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge a sample of price data with client to analyze price exposure\n",
    "if 'id' in client_df.columns and 'id' in price_df.columns:\n",
    "    # take price time series for a random sample of 4 customers and plot\n",
    "    sample_ids = price_df['id'].drop_duplicates().sample(4, random_state=42).tolist()\n",
    "    df_sample = price_df[price_df['id'].isin(sample_ids)].copy()\n",
    "    # pivot for plotting monthly price_off_peak_var where available\n",
    "    if 'price_date' in df_sample.columns:\n",
    "        for pid in sample_ids:\n",
    "            tmp = df_sample[df_sample['id']==pid].sort_values('price_date')\n",
    "            if 'price_off_peak_var' in tmp.columns:\n",
    "                plt.plot(tmp['price_date'], tmp['price_off_peak_var'], marker='o', label=str(pid))\n",
    "        plt.xlabel('Price date')\n",
    "        plt.ylabel('price_off_peak_var')\n",
    "        plt.title('Sample customers: price_off_peak_var time series')\n",
    "        plt.legend()\n",
    "        plt.gcf().autofmt_xdate()\n",
    "        plt.show()\n",
    "else:\n",
    "    print(\"Cannot merge — missing 'id' in one of the datasets.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80285e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Churn by category for a few categorical columns\n",
    "cat_cols = [c for c in ['channel_sales','has_gas','origin_up'] if c in client_df.columns]\n",
    "for c in cat_cols:\n",
    "    temp = client_df.groupby([c,'churn']).size().unstack(fill_value=0)\n",
    "    # convert to percentage\n",
    "    temp_pct = temp.div(temp.sum(axis=1), axis=0)*100\n",
    "    display(temp_pct)\n",
    "    plot_stacked_bars(temp_pct.transpose(), f\"Churn by {c}\", (6,4), legend_='lower right')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22532412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation of numeric features vs churn (point biserial via corr with churn)\n",
    "num = client_df.select_dtypes(include=[np.number]).drop(columns=['churn'], errors='ignore')\n",
    "if 'churn' in client_df.columns:\n",
    "    corr_with_churn = num.apply(lambda x: x.corr(client_df['churn']))\n",
    "    display(corr_with_churn.sort_values(ascending=False).head(20))\n",
    "\n",
    "# Boxplot example: net_margin (if exists) by churn\n",
    "if 'net_margin' in client_df.columns:\n",
    "    fig, ax = plt.subplots(figsize=(8,6))\n",
    "    client_df.boxplot(column='net_margin', by='churn', ax=ax)\n",
    "    plt.title(\"Net margin by churn\")\n",
    "    plt.suptitle('')\n",
    "    plt.xlabel(\"Churn\")\n",
    "    plt.ylabel(\"Net margin\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adeb6bf2",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "- Feature engineering (tenure, avg monthly consumption, price change exposure)\n",
    "- Statistical tests to validate price sensitivity hypothesis (t-tests, regression coefficients)\n",
    "- Build predictive models (logistic regression, tree-based) and measure feature importance\n",
    "\n",
    "---\n",
    "\n",
    "**File saved:** `EDA_BCGX_Task2.ipynb`"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
